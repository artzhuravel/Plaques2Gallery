Metadata-Version: 2.4
Name: plaques2gallery
Version: 1.0.0
Summary: Automated pipeline to match museum plaque photographs to artwork images
Author: Plaques2Gallery Author
License: MIT
Project-URL: Homepage, https://github.com/yourusername/Plaques2Gallery
Project-URL: Repository, https://github.com/yourusername/Plaques2Gallery
Keywords: museum,art,ocr,web-scraping,image-recognition
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: End Users/Desktop
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Multimedia :: Graphics
Classifier: Topic :: Scientific/Engineering :: Image Recognition
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: opencv-python>=4.5.0
Requires-Dist: numpy>=1.20.0
Requires-Dist: pytesseract>=0.3.8
Requires-Dist: Pillow>=9.0.0
Requires-Dist: google-generativeai>=0.3.0
Requires-Dist: google-api-python-client>=2.0.0
Requires-Dist: playwright>=1.30.0
Requires-Dist: aiohttp>=3.8.0
Requires-Dist: python-docx>=0.8.11
Requires-Dist: python-dotenv>=1.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Dynamic: license-file

# Plaques2Gallery

An automated pipeline that matches museum plaque photographs to artwork images using OCR, AI-powered text cleaning, and web scraping.

## Overview

Wherever I go, I try to explore the local art scene. Along with fairs, music festivals, and theater performances, I always make time to visit at least one art gallery or museum.

Since I've been traveling quite a lot over the past two years, I've encountered hundreds of artworks. Whenever a piece resonates with me, I want to capture that moment. But I quickly realized that photographing the artwork itself wasn't very helpful—without knowing the title or artist, those photos lacked context. So I started doing something more practical: I took pictures of the museum plaques that are usually displayed next to the artworks.

This solved one problem but created another. Now my photo library is filled with images of plaques from museums around the world—each one informative, but completely detached from the visual memory that triggered my interest in the first place. Without the artwork itself, it's hard to recall why I found a particular piece compelling.

Manually looking up and downloading each painting would be the most accurate solution, but with hundreds of plaques, that would take far too long. So I built this pipeline to automate the process.

## How It Works

1. **Extract plaque text** — The pipeline loops through all plaque images and uses OCR to extract readable text. The photos vary in quality and the plaques follow different formats across museums, so OCR isn't always perfect.

2. **Clean and parse text** — To handle noisy or inconsistent OCR output, Google's Gemini model extracts a clean, standardized format: "Painting Title by Artist".

3. **Search for artwork online** — Using Google's Custom Search API, the pipeline searches for each painting and collects the top 3 URLs that might contain images. Due to API quotas, images are processed in batches of 70 per day.

4. **Download the best matching image** — Using Playwright, the pipeline loads each page and selects the largest visible image. It also handles cookie banners and prioritizes reliable sources like museum websites or Wikipedia.

## Installation

### Prerequisites

- Python 3.10+
- [Tesseract OCR](https://github.com/tesseract-ocr/tesseract) installed on your system
- Playwright browsers installed

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/Plaques2Gallery.git
   cd Plaques2Gallery
   ```

2. **Create a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install the package**
   ```bash
   pip install -e .
   ```

   Or install dependencies only:
   ```bash
   pip install -r requirements.txt
   ```

4. **Install Playwright browsers**
   ```bash
   playwright install chromium
   ```

5. **Configure environment variables**

   Copy the example environment file and add your API keys:
   ```bash
   cp .env.example .env
   ```

   Edit `.env` with your credentials:
   - `GEMINI_API_KEY` — Get from [Google AI Studio](https://aistudio.google.com/app/apikey)
   - `GOOGLE_SEARCH_API_KEY` — Get from [Google Cloud Console](https://console.cloud.google.com/apis/credentials)
   - `GOOGLE_CSE_ID` — Create at [Programmable Search Engine](https://programmablesearchengine.google.com/)

6. **Create required directories**
   ```bash
   mkdir -p museum_plaques intermediate_results extracted_images
   ```

## Usage

1. **Add your plaque images** — Place your museum plaque photos in the `museum_plaques/` directory.

2. **Run the pipeline** — Open `notebooks/main_pipeline.ipynb` in Jupyter and execute cells sequentially:
   - Cells under "OCR Text Extraction" process plaque images
   - Cells under "Cleaning Extracted Text" use Gemini to standardize text
   - Cells under "Internet Search" find artwork URLs (limited by daily API quota)
   - Cells under "Extract Images" download artwork images

3. **Review results** — Output is saved to:
   - `final_results.json` — Structured data with painting names, sources, and paths
   - `final_results.docx` — Formatted document with results
   - `extracted_images/` — Downloaded artwork images

## Project Structure

```
Plaques2Gallery/
├── plaques2gallery/              # Main package
│   ├── __init__.py               # Package exports
│   ├── ocr_text_extraction.py    # Image preprocessing and OCR
│   ├── clean_museum_plaques_text.py  # Gemini-based text cleaning
│   ├── web_search.py             # Google Custom Search wrapper
│   └── web_scraping.py           # Playwright-based image extraction
├── notebooks/
│   └── main_pipeline.ipynb       # Main orchestration notebook
├── pyproject.toml                # Package configuration
├── requirements.txt              # Python dependencies
├── .env.example                  # Environment variables template
├── .gitignore                    # Git ignore rules
└── LICENSE                       # MIT License
```

## Output Format

Each successfully matched artwork is recorded with:
- The painting name (title and artist)
- The original museum plaque image filename
- The path to the downloaded image
- The museum location (if determinable from URL)
- The source URL of the retrieved image

## Sample Data

- [Museum plaque images](https://drive.google.com/file/d/1H1zy3ZTO6ifsAMLCEdFP_aLyJtOTpcia/view?usp=sharing)
- [Intermediate pipeline results](https://drive.google.com/drive/folders/1osaGwaLuin4FK0EJ4FtkWqKdhv1wTzCT?usp=sharing)
- [Sample output results](https://drive.google.com/drive/folders/1rQnohPbec1yzm09i1X2RnVIoCfMJ-QNk?usp=sharing)

## Limitations

- OCR accuracy varies based on image quality and plaque format
- Google Custom Search API has daily quota limits (100 queries/day free tier)
- Some websites may block automated scraping or require captcha verification
- The "largest image" heuristic doesn't always select the correct artwork

Results may require manual review and correction for best accuracy.

## License

MIT License — see [LICENSE](LICENSE) for details.
